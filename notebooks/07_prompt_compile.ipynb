{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import datasets\n",
    "import imodelsx.metrics\n",
    "import numpy as np\n",
    "sys.path.append('../experiments/')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import sys\n",
    "from os.path import join\n",
    "import datasets\n",
    "from typing import Dict, List\n",
    "from dict_hash import sha256\n",
    "import numpy as np\n",
    "import openai\n",
    "openai.api_key = open(os.path.expanduser('~/.openai_api_key')).read().strip()\n",
    "import imodelsx.treeprompt.stump\n",
    "\n",
    "from tprompt.compiler.evaluator import PromptHooker, modify_activations\n",
    "from tprompt.compiler import compiling\n",
    "import tprompt.compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load prompt vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "checkpoint = 'gpt2-xl'\n",
    "prompts = [\n",
    "    # \" This review of a movie is\",\n",
    "    # \" Positive or Negative? The movie was\",\n",
    "    # \" The sentiment of the movie was\",\n",
    "    # \" The plot of the movie was really\",\n",
    "    # \" The acting in the movie was\",\n",
    "    \" This movie is\",\n",
    "    \" Positive or Negative? The movie was\",\n",
    "    \" The sentiment of the movie was\",\n",
    "    \" The plot of the movie was really\",\n",
    "    \" The acting in the movie was\",\n",
    "]\n",
    "# note: also requires specifying the layer for the hook below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instructions here for setting up vec2text\n",
    "# !pip install vec2text\n",
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_soft_prompt = compiling.get_avg_soft_prompt(checkpoint, prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The movie was a movie. The plot was very interesting. The movie was actually quite funny. The movie was filmed in a very realistic manner. The movie is'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "avg_text = tprompt.compiler.compiling.get_avg_inverted_text_prompt(prompts)\n",
    "\n",
    "# remove any repeated full senteces in the string\n",
    "\n",
    "\n",
    "def remove_repeated_sentences(text):\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences = list(dict.fromkeys(sentences))\n",
    "    return ' '.join(sentences)\n",
    "\n",
    "\n",
    "avg_text = remove_repeated_sentences(avg_text[0]).strip()\n",
    "print(repr(avg_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aef35869c3e46438ac0c0142bcc1f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dset_train = datasets.load_dataset('rotten_tomatoes')['train']\n",
    "dset_train = dset_train.select(np.random.choice(\n",
    "    len(dset_train), size=100, replace=False))\n",
    "# dset_val = datasets.load_dataset('rotten_tomatoes')['validation']\n",
    "# dset_val = dset_val.select(np.random.choice(\n",
    "#     len(dset_val), size=100, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "\n",
      "Inverted avg prompt\n",
      "Prompt 0: The movie was a movie. The plot was very interesting. The movie was actually quite funny. The movie was filmed in a very realistic manner. The movie is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            5.47it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged inverted prompt ->  0.46\n",
      "------------------------\n",
      "\n",
      "Individual prompts\n",
      "Prompt 0:  This movie is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            5.37it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1:  Positive or Negative? The movie was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            5.60it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2:  The sentiment of the movie was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            5.71it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 3:  The plot of the movie was really\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            5.52it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4:  The acting in the movie was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            5.66it/s]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5:  The movie was a movie.  The plot was a movie.  The actors were really good.  The movie is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  This movie is -> 0.67\n",
      "1  Positive or Negative? The movie was -> 0.51\n",
      "2  The sentiment of the movie was -> 0.47\n",
      "3  The plot of the movie was really -> 0.74\n",
      "4  The acting in the movie was -> 0.55\n",
      "5  The movie was a movie.  The plot was a movie.  The actors were really good.  The movie is -> 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "verbalizer = {0: \" Negative.\", 1: \" Positive.\"}\n",
    "kwargs = dict(\n",
    "    checkpoint=checkpoint,\n",
    "    verbalizer=verbalizer,\n",
    "    cache_prompt_features_dir=None,\n",
    "    random_state=42,\n",
    "    prompt_at_start_or_end='end',\n",
    "    prompt_template=\"{example}{prompt}\",\n",
    ")\n",
    "# m = PromptHooker(\n",
    "#     prompts=[prompts[0]],\n",
    "#     hook_weights=avg_soft_prompt,\n",
    "#     **kwargs\n",
    "# )\n",
    "# m.fit(dset_train[\"text\"], dset_train[\"label\"])\n",
    "# acc_avg = m.prompt_accs_[0]\n",
    "# print('\\n**Soft Averaged** ->', acc_avg)\n",
    "# print('------------------------')\n",
    "\n",
    "\n",
    "print('------------------------')\n",
    "print('\\n**Inverted avg prompt**')\n",
    "\n",
    "m = PromptHooker(\n",
    "    prompts=[avg_text],\n",
    "    hook_weights=None,\n",
    "    **kwargs\n",
    ")\n",
    "m.fit(dset_train[\"text\"], dset_train[\"label\"])\n",
    "print('Averaged inverted prompt -> ', m.prompt_accs_[0])\n",
    "\n",
    "\n",
    "print('------------------------')\n",
    "print('\\n**Individual prompts**')\n",
    "m = PromptHooker(\n",
    "    prompts=prompts,\n",
    "    hook_weights=None,\n",
    "    **kwargs\n",
    ")\n",
    "m.fit(dset_train[\"text\"], dset_train[\"label\"])\n",
    "\n",
    "accs0 = deepcopy(m.prompt_accs_)\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(i, prompt, '->', accs0[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tok_lens = [len(tok.encode(prompt)) for prompt in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = PromptHooker(\n",
    "    checkpoint=checkpoint,\n",
    "    # 3 different prompts with same len\n",
    "    prompts=[prompts[0], prompts[2], prompts[3]],\n",
    "    verbalizer=verbalizer,\n",
    "    cache_prompt_features_dir=None,\n",
    "    random_state=42,\n",
    "    hook_weights=avg_soft_prompt,\n",
    "    prompt_at_start_or_end='end',\n",
    "    prompt_template=\"{example}{prompt}\",\n",
    ")\n",
    "m.fit(dset_train[\"text\"], dset_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.prompt_accs_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
